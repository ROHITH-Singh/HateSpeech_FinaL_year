{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deploying.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO6bJ8WceaCDsJT0rgau3cP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ROHITH-Singh/HateSpeech_FinaL_year/blob/main/deploying.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PfL7INoFUJHq"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVkJnhxFUNG2",
        "outputId": "b4a202aa-899b-4255-eb4c-9dea5dae8fa4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "import itertools as it\n",
        "import pickle\n",
        "import os\n",
        "from  pathlib import Path\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords                  # module for stop words that come with NLTK\n",
        "from nltk.stem.wordnet import WordNetLemmatizer    # module for lemmatization\n",
        "from nltk import word_tokenize, pos_tag            # tokenization and Part of Speech tagging\n",
        "\n",
        "nltk.download('stopwords') #stopwords used to preprocess the corpus\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "stopwords_english = stopwords.words('english')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OYaB6qJUUFY",
        "outputId": "9f71a9a4-7c23-4924-9856-1b95c366ad3a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logs_toxic = pickle.load(open('/content/drive/MyDrive/final_year project/model log/logs_toxic.pkl','rb'))\n",
        "models_toxic = pickle.load(open('/content/drive/MyDrive/final_year project/model log/models_toxic.pkl','rb'))\n",
        "logs_identity_hate = pickle.load(open('/content/drive/MyDrive/final_year project/model log/logs_identity_hate.pkl','rb'))\n",
        "models_identity_hate = pickle.load(open('/content/drive/MyDrive/final_year project/model log/models_identity_hate.pkl','rb'))\n",
        "logs_insult=  pickle.load(open('/content/drive/MyDrive/final_year project/model log/logs_insult.pkl','rb'))\n",
        "models_insult =  pickle.load(open('/content/drive/MyDrive/final_year project/model log/models_insult.pkl','rb'))\n",
        "logs_obscene = pickle.load(open('/content/drive/MyDrive/final_year project/model log/logs_obscene.pkl','rb'))\n",
        "models_obscene = pickle.load(open('/content/drive/MyDrive/final_year project/model log/models_obscene.pkl','rb'))\n",
        "logs_severe_toxic = pickle.load(open('/content/drive/MyDrive/final_year project/model log/logs_severe_toxic.pkl','rb'))\n",
        "models_severe_toxic = pickle.load(open('/content/drive/MyDrive/final_year project/model log/models_severe_toxic.pkl','rb'))\n",
        "logs_threat = pickle.load(open('/content/drive/MyDrive/final_year project/model log/logs_threat.pkl','rb'))\n",
        "models_threat = pickle.load(open('/content/drive/MyDrive/final_year project/model log/models_threat.pkl','rb'))\n",
        "tfidf_vec = pickle.load(open('/content/drive/MyDrive/final_year project/model log/tfidf_vectorizer.pkl','rb'))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2Q1vXx7zUhGj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30ec491f-d981-4099-9717-b5895f8b8051"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:338: UserWarning: Trying to unpickle estimator LogisticRegression from version 1.0.1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:338: UserWarning: Trying to unpickle estimator TfidfTransformer from version 1.0.1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:338: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 1.0.1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
            "  UserWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Let''s define a function that preprocesses a text\n",
        "\n",
        "def preprocess(corpus):\n",
        "    \n",
        "    '''\n",
        "    From a string, make text lowercase, remove hyperlinks, punctuation, word containing numbers, stopwords.\n",
        "    Input : a list of strings\n",
        "    Output : a list of tokens stored in a generator (yield)\n",
        "    '''\n",
        "\n",
        "    for text in corpus:\n",
        "\n",
        "        text = text.lower()                                               # Lowercase\n",
        "        text = re.sub(r'https?://[^\\s\\n\\r]+', '', text)                   # Remove links\n",
        "        text = re.sub('[%s]' % re.escape(string.punctuation), '', text)   # Remove punctuation\n",
        "        text = re.sub('\\w*\\d\\w*', '', text)                               # Remove words containing numbers\n",
        "    \n",
        "        yield ' '.join([word for word in text.split(' ') if word not in stopwords_english]) # Return a generator \n",
        "\n"
      ],
      "metadata": {
        "id": "NEN9epjbWAoa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comment = [\"bitch\"]\n",
        "clean_comments= list(preprocess(comment))\n",
        "print(clean_comments)\n",
        "word_emb = tfidf_vec.transform(clean_comments)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBEwDrmNWRhF",
        "outputId": "8b22436f-4164-4ae9-9121-afcc1ea4fed3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['bitch']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(models_toxic.predict(word_emb.dot(logs_toxic))) \n",
        "print(models_identity_hate.predict(word_emb.dot(logs_identity_hate)))\n",
        "print(models_insult.predict(word_emb.dot(logs_insult)))\n",
        "print(models_obscene.predict(word_emb.dot(logs_obscene)))\n",
        "print(models_severe_toxic.predict(word_emb.dot(logs_severe_toxic)))\n",
        "print(models_threat.predict(word_emb.dot(logs_threat)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8SRm5EnWuuI",
        "outputId": "9d0a1048-4f94-47e9-d8c9-d96543009323"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\n",
            "[0]\n",
            "[1]\n",
            "[1]\n",
            "[0]\n",
            "[0]\n"
          ]
        }
      ]
    }
  ]
}